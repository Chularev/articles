{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mprun_demo import test_me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Filename: /mnt/heap/My folder/python/articles/mprun_demo.py\n",
       "\n",
       "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
       "=============================================================\n",
       "     6    260.7 MiB    260.7 MiB           1   def test_me(rows,columns):\n",
       "     7                                             #for i in range(100):\n",
       "     8    272.0 MiB     11.3 MiB           1       M1 = np.random.rand(rows, columns)\n",
       "     9    283.6 MiB     11.6 MiB           1       M2 = np.random.rand(columns, rows)\n",
       "    10    306.1 MiB     22.5 MiB           1       M3 = M1 @ M2\n",
       "    11                                         \n",
       "    12    306.1 MiB      0.0 MiB           1       M_1 = torch.from_numpy(M1)\n",
       "    13    306.1 MiB      0.0 MiB           1       M_2 = torch.from_numpy(M2)\n",
       "    14    306.1 MiB      0.0 MiB           1       M_1.requires_grad = False\n",
       "    15    306.1 MiB      0.0 MiB           1       M_2.requires_grad = False\n",
       "    16    332.8 MiB     26.7 MiB           1       M_3 = M_1 @ M_2\n",
       "    17                                         \n",
       "    18    332.8 MiB      0.0 MiB           1       cuda = torch.device('cuda:0')\n",
       "    19   3043.8 MiB   2710.9 MiB           1       M1_CUDA = M_1.to(cuda)\n",
       "    20   3043.8 MiB      0.0 MiB           1       M2_CUDA = M_2.to(cuda)\n",
       "    21                                         \n",
       "    22   3043.8 MiB      0.0 MiB           1       M3_CUDA = M1_CUDA @ M2_CUDA\n",
       "    23   3043.8 MiB      0.0 MiB           1       cpu = torch.device('cpu')\n",
       "    24   3043.8 MiB      0.0 MiB           1       del M1_CUDA\n",
       "    25   3043.8 MiB      0.0 MiB           1       del M2_CUDA\n",
       "    26   3043.8 MiB      0.0 MiB           1       del M3_CUDA\n",
       "    27   3043.8 MiB      0.0 MiB           1       with torch.cuda.device('cuda:0'):\n",
       "    28   3043.8 MiB      0.0 MiB           1           torch.cuda.synchronize(device='cuda:0')\n",
       "    29   3043.8 MiB      0.0 MiB           1           torch.cuda.empty_cache()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%mprun -f test_me test_me(1500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 0.273218 s\n",
       "File: /mnt/heap/My folder/python/articles/mprun_demo.py\n",
       "Function: test_me at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                           def test_me(rows,columns):\n",
       "     7                                               #for i in range(100):\n",
       "     8         1      13235.0  13235.0      4.8      M1 = np.random.rand(rows, columns)\n",
       "     9         1      12290.0  12290.0      4.5      M2 = np.random.rand(columns, rows)\n",
       "    10         1      87018.0  87018.0     31.8      M3 = M1 @ M2\n",
       "    11                                           \n",
       "    12         1         32.0     32.0      0.0      M_1 = torch.from_numpy(M1)\n",
       "    13         1          6.0      6.0      0.0      M_2 = torch.from_numpy(M2)\n",
       "    14         1          7.0      7.0      0.0      M_1.requires_grad = False\n",
       "    15         1          2.0      2.0      0.0      M_2.requires_grad = False\n",
       "    16         1     116998.0 116998.0     42.8      M_3 = M_1 @ M_2\n",
       "    17                                           \n",
       "    18         1         21.0     21.0      0.0      cuda = torch.device('cuda:0')\n",
       "    19         1       3521.0   3521.0      1.3      M1_CUDA = M_1.to(cuda)\n",
       "    20         1       3169.0   3169.0      1.2      M2_CUDA = M_2.to(cuda)\n",
       "    21                                           \n",
       "    22         1        452.0    452.0      0.2      M3_CUDA = M1_CUDA @ M2_CUDA\n",
       "    23         1         15.0     15.0      0.0      cpu = torch.device('cpu')\n",
       "    24         1         17.0     17.0      0.0      del M1_CUDA\n",
       "    25         1          2.0      2.0      0.0      del M2_CUDA\n",
       "    26         1          2.0      2.0      0.0      del M3_CUDA\n",
       "    27         1         71.0     71.0      0.0      with torch.cuda.device('cuda:0'):\n",
       "    28         1      36036.0  36036.0     13.2          torch.cuda.synchronize(device='cuda:0')\n",
       "    29         1        324.0    324.0      0.1          torch.cuda.empty_cache()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -f test_me test_me(1500, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cu102\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from large pool |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from small pool |       0 B  |       0 KB |       0 KB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from large pool |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from small pool |       0 B  |       0 KB |       0 KB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from large pool |       0 B  |   43008 KB |   86016 KB |   86016 KB |\n",
      "|       from small pool |       0 B  |       0 KB |       0 KB |       0 KB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       3    |       6    |       6    |\n",
      "|       from large pool |       0    |       3    |       6    |       6    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       3    |       6    |       6    |\n",
      "|       from large pool |       0    |       3    |       6    |       6    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       3    |       6    |       6    |\n",
      "|       from large pool |       0    |       3    |       6    |       6    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-20ef81218aaa>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-20ef81218aaa>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ======================================================\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "======================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Scalene\n",
    "%load_ext scalene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = np.random.rand(10100,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M2 = np.random.rand(1000,10100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mul_matrix(M1,M2):\n",
    "    M1 = np.random.rand(10100,1000)\n",
    "    M2 = np.random.rand(1000,10100)\n",
    "    m3 = M1 @ M2\n",
    "    return m3 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mul_matrix(M1,M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scrun --profile-all mul_matrix(M1,M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "=========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = torch.from_numpy(M1)\n",
    "m4 = torch.from_numpy(M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = m3.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = m4.to(cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = m3 @ m4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scalene --reduced-profile\n",
    "# Profile more than one line of code in a cell\\\n",
    "MR = M1 * M2\n",
    "MR += 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%scrun --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_me1():\n",
    "    return np.array(np.random.uniform(0, 100, size=(10**8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test_me():\n",
    "    for i in range(6):\n",
    "        x = np.array(range(10**7))\n",
    "        y = test_me1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profile just one line of code\n",
    "%scrun --reduced-profile test_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scalene --reduced-profile\n",
    "# Profile more than one line of code in a cell\n",
    "x = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
